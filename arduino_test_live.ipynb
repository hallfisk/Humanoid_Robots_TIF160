{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load YOLOv8 large model\n",
    "model = YOLO('yolov8l.pt')\n",
    "model.to('cpu')\n",
    "\n",
    "def detect_fruit_and_save_image(image, target_fruit='apple', output_path='output_image.jpg'):\n",
    "    # Resize the image for YOLO detection (optional)\n",
    "    img_resized = cv2.resize(image, (1300, 900))\n",
    "\n",
    "    # Set mouse callback for getting coordinates\n",
    "    def get_coordinates(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            print(f\"Coordinates: ({x}, {y})\")\n",
    "            coordinates_of_box.append((x, y))\n",
    "\n",
    "    coordinates_of_box = []\n",
    "\n",
    "    # Display the image and set mouse callback\n",
    "    cv2.imshow('Image', img_resized)\n",
    "    cv2.setMouseCallback('Image', get_coordinates)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Use the YOLO model to detect objects\n",
    "    results = model(img_resized)\n",
    "\n",
    "    # Get class names\n",
    "    class_names = model.names\n",
    "\n",
    "    # Find the class ID for the target fruit\n",
    "    target_fruit_class_id = None\n",
    "    for class_id, name in class_names.items():\n",
    "        if name == target_fruit:\n",
    "            target_fruit_class_id = class_id\n",
    "            break\n",
    "\n",
    "    if target_fruit_class_id is None:\n",
    "        print(f\"Error: The target fruit '{target_fruit}' is not in the YOLO dataset.\")\n",
    "        return None\n",
    "\n",
    "    target_fruit_positions = []\n",
    "\n",
    "    # Loop over detections\n",
    "    for detection in results[0].boxes:\n",
    "        class_id = int(detection.cls)\n",
    "\n",
    "        xmin, ymin, xmax, ymax = map(int, detection.xyxy[0])\n",
    "        x_center = (xmin + xmax) // 2\n",
    "        y_center = (ymin + ymax) // 2\n",
    "\n",
    "        if class_id == target_fruit_class_id:\n",
    "            cv2.circle(img_resized, (x_center, y_center), 10, (0, 0, 255), -1)\n",
    "            target_fruit_positions.append((x_center, y_center))\n",
    "        elif class_id in [46, 47, 49, 50, 51]:\n",
    "            cv2.circle(img_resized, (x_center, y_center), 10, (255, 0, 0), -1)\n",
    "\n",
    "    for (x, y) in coordinates_of_box:\n",
    "        cv2.circle(img_resized, (x, y), 10, (0, 255, 0), -1)\n",
    "\n",
    "    # Save the detection image\n",
    "    cv2.imwrite(output_path, img_resized)\n",
    "\n",
    "    if target_fruit_positions:\n",
    "        print(f\"Detected {target_fruit} at positions: {target_fruit_positions}\")\n",
    "    else:\n",
    "        print(f\"No {target_fruit} detected in the image.\")\n",
    "\n",
    "    x_zero, y_zero = coordinates_of_box[2]\n",
    "    x_fruit, y_fruit = target_fruit_positions[0]\n",
    "\n",
    "    box_size_x_mm = 282  # mm\n",
    "    box_size_y_mm = 240  # mm\n",
    "    box_size_diag_mm = (box_size_x_mm**2 + box_size_y_mm**2)**0.5  # mm\n",
    "\n",
    "    # Calculate pixel distances\n",
    "    box_size_x_pixels_mean = np.mean([np.linalg.norm(np.array(coordinates_of_box[i]) - np.array(coordinates_of_box[i+1])) for i in range(0, 4, 2)])\n",
    "    box_size_y_pixels_mean = np.mean([np.linalg.norm(np.array(coordinates_of_box[i]) - np.array(coordinates_of_box[i+3])) for i in range(0, 2)])\n",
    "\n",
    "    mm_per_pixel = (box_size_x_mm / box_size_x_pixels_mean + box_size_y_mm / box_size_y_pixels_mean) / 2\n",
    "\n",
    "    relative_x_fruit_pixels = abs(x_fruit - x_zero)\n",
    "    relative_y_fruit_pixels = abs(y_fruit - y_zero)\n",
    "\n",
    "    relative_x_fruit_mm = relative_x_fruit_pixels * mm_per_pixel\n",
    "    relative_y_fruit_mm = relative_y_fruit_pixels * mm_per_pixel\n",
    "\n",
    "    print(f'\\nPixels from {target_fruit} to bottom-right corner:')\n",
    "    print('x (pixels):', relative_x_fruit_pixels)\n",
    "    print('x (mm):', relative_x_fruit_mm)\n",
    "    print('y (pixels):', relative_y_fruit_pixels)\n",
    "    print('y (mm):', relative_y_fruit_mm)\n",
    "\n",
    "    return relative_x_fruit_mm, relative_y_fruit_mm\n",
    "\n",
    "# Open live camera feed and capture image\n",
    "def capture_image_from_camera():\n",
    "    cap = cv2.VideoCapture(0)  # Change 0 to your USB camera index if needed\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return None\n",
    "\n",
    "    print(\"Press 'C' to capture the image.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow('Live Camera Feed', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            print(\"Image captured.\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            return frame\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return None\n",
    "\n",
    "# Main program\n",
    "image = capture_image_from_camera()\n",
    "if image is not None:\n",
    "    output_image = 'box_with_fruits_and_edges_marked.jpg'\n",
    "    fruits_list = ['banana', 'apple', 'orange']\n",
    "    fruit_index = int(input('Choose index following [0, 1, 2] = [banana, apple, orange]: '))\n",
    "    target_fruit = fruits_list[fruit_index]\n",
    "\n",
    "    relative_x_fruit_mm, relative_y_fruit_mm = detect_fruit_and_save_image(image, target_fruit, output_image)\n",
    "\n",
    "# Distances from bottom-right corner of box to the base system of Hubert\n",
    "box_bottom_right_corner_to_base_system_x = 60 #mm\n",
    "box_bottom_right_corner_to_base_system_y = -120  #mm\n",
    "box_bottom_right_corner_to_base_system_z = 94 #mm\n",
    "\n",
    "if fruit_index == 0: #banana\n",
    "    relative_z_fruit_mm = 70 #start with set value to begin with\n",
    "else: #apple or orange\n",
    "    relative_z_fruit_mm = 70\n",
    "\n",
    "fruit_position_base_system_x = box_bottom_right_corner_to_base_system_x + relative_y_fruit_mm\n",
    "fruit_position_base_system_y = box_bottom_right_corner_to_base_system_y + relative_x_fruit_mm\n",
    "fruit_position_base_system_z = box_bottom_right_corner_to_base_system_z + relative_z_fruit_mm\n",
    "\n",
    "fruit_position_base_system = [fruit_position_base_system_x, fruit_position_base_system_y, fruit_position_base_system_z]\n",
    "\n",
    "print(\"\\nFruit pos base system (mm): \", fruit_position_base_system)\n",
    "\n",
    "class InverseKinematicsNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InverseKinematicsNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 64)  # Input layer (x, y, z) -> 64 neurons\n",
    "        self.fc2 = nn.Linear(64, 128)  # Hidden layer -> 128 neurons\n",
    "        self.fc3 = nn.Linear(128, 256)  # Hidden layer -> 128 neurons\n",
    "        self.fc4 = nn.Linear(256, 128)  # Hidden layer -> 128 neurons\n",
    "        self.fc5 = nn.Linear(128, 64)  # Hidden layer -> 64 neurons\n",
    "        self.fc6 = nn.Linear(64, 3)   # Output layer -> (theta_1, theta_2, theta_3)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.leaky_relu(self.fc3(x))\n",
    "        x = self.leaky_relu(self.fc4(x))\n",
    "        x = self.leaky_relu(self.fc5(x))\n",
    "        x = self.fc6(x)  # Output angles in radians\n",
    "        return x\n",
    "\n",
    "model = InverseKinematicsNN()\n",
    "model.load_state_dict(torch.load('NN_50_000epoch_diffLATESTV2'))\n",
    "\n",
    "test_position = torch.tensor(fruit_position_base_system, dtype=torch.float32)/1000\n",
    "print('\\nTest pos (m): ', test_position)\n",
    "print()\n",
    "\n",
    "# Put your model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    predicted_angles = model(test_position)  # Predict the joint angles from the model\n",
    "    predicted_angles_rad = predicted_angles.detach().numpy()\n",
    "\n",
    "print('Predicted angles [rad]: ', predicted_angles_rad)\n",
    "predicted_angles_deg = predicted_angles_rad*180/np.pi\n",
    "print('Predicted angles [deg]: ', predicted_angles_deg)\n",
    "print()\n",
    "\n",
    "def angle_to_millisec(ls): #body, shoulder, elbow\n",
    "    theta1, theta2, theta3 = ls\n",
    "    \n",
    "    body_servo = 540 + ((-theta1+90)/180) * (2320 - 540) \n",
    "    shoulder_servo = 1250 + (theta2/90 * (2050 - 1250))\n",
    "    elbow_servo = 550 + ((theta3+90)/180 * (2370 - 550))\n",
    "    \n",
    "     # Clamp the servo positions to their respective limits\n",
    "    body_servo = max(540, min(body_servo, 2320))  # Min: 540, Max: 2320\n",
    "    shoulder_servo = max(1250, min(shoulder_servo, 2050))  # Min: 1250, Max: 2050\n",
    "    elbow_servo = max(550, min(elbow_servo, 2370))  # Min: 550, Max: 2370\n",
    "\n",
    "    return body_servo, shoulder_servo, elbow_servo\n",
    "\n",
    "body_servo, shoulder_servo, elbow_servo = angle_to_millisec(predicted_angles_deg)\n",
    "\n",
    "print('Body servo [ms]: ', body_servo)\n",
    "print('Shoulder servo [ms]: ', shoulder_servo)\n",
    "print('Elbow servo [ms]: ', elbow_servo)\n",
    "print()\n",
    "\n",
    "import serial\n",
    "import time\n",
    "\n",
    "def send_command(arduino, body, shoulder, elbow, gripper=None):\n",
    "    # Send the servo values to the Arduino as a single string\n",
    "    servo_data = f\"{body},{shoulder},{elbow}\"\n",
    "    if gripper is not None:\n",
    "        servo_data += f\",{gripper}\"  # Add gripper value if specified\n",
    "    servo_data += \"\\n\"\n",
    "    arduino.write(servo_data.encode('utf-8'))\n",
    "    time.sleep(1)  # Give some time for Arduino to process the command\n",
    "\n",
    "# Establish serial connection\n",
    "port_name = '/dev/cu.usbmodem101'\n",
    "arduino = serial.Serial(port=port_name, baudrate=57600, timeout=.2)\n",
    "arduino.dtr = False  # Prevent Arduino reset on connection\n",
    "time.sleep(2)  # Delay to stabilize serial connection\n",
    "\n",
    "# Send the initial servo positions to the Arduino\n",
    "send_command(arduino, body_servo, shoulder_servo, elbow_servo)\n",
    "\n",
    "# Wait for Arduino response (optional, can be removed if not needed)\n",
    "response = arduino.readline().decode('utf-8').strip()\n",
    "if response:\n",
    "    print(\"Arduino says:\", response)\n",
    "\n",
    "# Wait for manual input from the user\n",
    "while True:\n",
    "    command = input(\"Enter 'close' to close the gripper and move the robot: \")\n",
    "    if command.lower() == \"close\":\n",
    "\n",
    "        print('OK')\n",
    "        \n",
    "        command += \"\\n\"\n",
    "        arduino.write(command.encode('utf-8'))\n",
    "        time.sleep(5)\n",
    "        \n",
    "        break  # End the loop and finish the program\n",
    "    else:\n",
    "        print(\"Unknown command. Please type 'close' to continue.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
